{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recordLinkage.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install recordlinkage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzOlc_r-Kc6g",
        "outputId": "42719726-c165-43da-f255-99ae231114c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting recordlinkage\n",
            "  Downloading recordlinkage-0.15-py3-none-any.whl (926 kB)\n",
            "\u001b[K     |████████████████████████████████| 926 kB 26.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2,>=1 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.4.1)\n",
            "Collecting jellyfish>=0.8.0\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1->recordlinkage) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1->recordlinkage) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<2,>=1->recordlinkage) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->recordlinkage) (3.1.0)\n",
            "Building wheels for collected packages: jellyfish\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73976 sha256=6111840ea8c11a1b6cbd53f7807436b725a233bc0e2e76da29c194519a3b0d76\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built jellyfish\n",
            "Installing collected packages: jellyfish, recordlinkage\n",
            "Successfully installed jellyfish-0.9.0 recordlinkage-0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://recordlinkage.readthedocs.io/en/latest/guides/link_two_dataframes.html"
      ],
      "metadata": {
        "id": "Z2Z1j_gPLwQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import recordlinkage\n",
        "from recordlinkage.datasets import load_febrl4\n",
        "\n",
        "dfA, dfB = load_febrl4()\n",
        "\n",
        "# Indexation step\n",
        "indexer = recordlinkage.Index()\n",
        "indexer.block(\"given_name\")\n",
        "candidate_links = indexer.index(dfA, dfB)\n",
        "\n",
        "# Comparison step\n",
        "compare_cl = recordlinkage.Compare()\n",
        "\n",
        "compare_cl.exact(\"given_name\", \"given_name\", label=\"given_name\")\n",
        "compare_cl.string(\"surname\", \"surname\", method=\"jarowinkler\", threshold=0.85, label=\"surname\")\n",
        "compare_cl.exact(\"date_of_birth\", \"date_of_birth\", label=\"date_of_birth\")\n",
        "compare_cl.exact(\"suburb\", \"suburb\", label=\"suburb\")\n",
        "compare_cl.exact(\"state\", \"state\", label=\"state\")\n",
        "compare_cl.string(\"address_1\", \"address_1\", threshold=0.85, label=\"address_1\")\n",
        "\n",
        "features = compare_cl.compute(candidate_links, dfA, dfB)\n",
        "\n",
        "# Classification step\n",
        "matches = features[features.sum(axis=1) > 3]\n",
        "print(len(matches))\n",
        "print(matches.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJS1l795KokS",
        "outputId": "932e1e99-600b-40f2-d8f4-8058b75ce6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3241\n",
            "                             given_name  surname  date_of_birth  suburb  \\\n",
            "rec_id_1     rec_id_2                                                     \n",
            "rec-2371-org rec-2371-dup-0           1      1.0              1       1   \n",
            "rec-3024-org rec-3024-dup-0           1      1.0              1       0   \n",
            "rec-4652-org rec-4652-dup-0           1      1.0              1       0   \n",
            "rec-4795-org rec-4795-dup-0           1      1.0              1       1   \n",
            "rec-1016-org rec-1016-dup-0           1      1.0              1       1   \n",
            "\n",
            "                             state  address_1  \n",
            "rec_id_1     rec_id_2                          \n",
            "rec-2371-org rec-2371-dup-0      1        1.0  \n",
            "rec-3024-org rec-3024-dup-0      1        0.0  \n",
            "rec-4652-org rec-4652-dup-0      1        1.0  \n",
            "rec-4795-org rec-4795-dup-0      1        1.0  \n",
            "rec-1016-org rec-1016-dup-0      0        1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://recordlinkage.readthedocs.io/en/latest/guides/data_deduplication.html"
      ],
      "metadata": {
        "id": "Z3gESmJ1RIyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import recordlinkage\n",
        "from recordlinkage.datasets import load_febrl1\n",
        "\n",
        "dfA = load_febrl1()\n",
        "\n",
        "# Indexation step\n",
        "indexer = recordlinkage.Index()\n",
        "indexer.block(left_on=\"given_name\")\n",
        "candidate_links = indexer.index(dfA)\n",
        "\n",
        "# Comparison step\n",
        "compare_cl = recordlinkage.Compare()\n",
        "\n",
        "compare_cl.exact(\"given_name\", \"given_name\", label=\"given_name\")\n",
        "compare_cl.string(\"surname\", \"surname\", method=\"jarowinkler\", threshold=0.85, label=\"surname\")\n",
        "compare_cl.exact(\"date_of_birth\", \"date_of_birth\", label=\"date_of_birth\")\n",
        "compare_cl.exact(\"suburb\", \"suburb\", label=\"suburb\")\n",
        "compare_cl.exact(\"state\", \"state\", label=\"state\")\n",
        "compare_cl.string(\"address_1\", \"address_1\", threshold=0.85, label=\"address_1\")\n",
        "\n",
        "features = compare_cl.compute(candidate_links, dfA)\n",
        "\n",
        "# Classification step\n",
        "matches = features[features.sum(axis=1) > 3]\n",
        "print(len(matches))\n",
        "print(matches.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEtOQTk1QkOQ",
        "outputId": "c0be46ba-3d9a-49d0-d1c8-50fd2b333d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317\n",
            "                             given_name  surname  date_of_birth  suburb  \\\n",
            "rec_id_1      rec_id_2                                                    \n",
            "rec-122-dup-0 rec-122-org             1      1.0              1       1   \n",
            "rec-183-org   rec-183-dup-0           1      1.0              1       1   \n",
            "rec-248-dup-0 rec-248-org             1      1.0              1       1   \n",
            "rec-373-dup-0 rec-373-org             1      1.0              1       1   \n",
            "rec-10-org    rec-10-dup-0            1      1.0              1       1   \n",
            "\n",
            "                             state  address_1  \n",
            "rec_id_1      rec_id_2                         \n",
            "rec-122-dup-0 rec-122-org        1        1.0  \n",
            "rec-183-org   rec-183-dup-0      1        1.0  \n",
            "rec-248-dup-0 rec-248-org        1        1.0  \n",
            "rec-373-dup-0 rec-373-org        1        1.0  \n",
            "rec-10-org    rec-10-dup-0       1        1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from recordlinkage.preprocessing import clean\n",
        "\n",
        "names = ['Mary-ann',\n",
        "        'Bob :)',\n",
        "        'Angel',\n",
        "        'Bob (alias Billy)',\n",
        "        None]\n",
        "print(names)\n",
        "s = pandas.Series(names)\n",
        "print(clean(s).values.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozgeiHAgZUl-",
        "outputId": "0748de75-f2b7-4be3-ce81-b1d8b9b7c8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mary-ann', 'Bob :)', 'Angel', 'Bob (alias Billy)', None]\n",
            "['mary ann', 'bob', 'angel', 'bob', None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import re\n",
        "\n",
        "\n",
        "url = 'https://plo.vn/xu-ly-can-bo-sai-pham-khong-vung-cam-du-chuc-vu-cao-den-dau-post683629.html'\n",
        "\n",
        "r = requests.get(url)\n",
        "\n",
        "soup = bs(r.text, \"html.parser\")\n",
        "content = soup.find_all(\"div\", class_=\"article__body\")\n",
        "content = bs(str(content[0]),'html.parser')\n",
        "content = soup.find_all(\"p\", style=\"text-align: justify;\")\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "  return re.sub('<.*?>', '', str(text))\n",
        "\n",
        "content = [clean_text(line) for line in content]\n",
        "print(len(content))\n",
        "for line in content:\n",
        "  print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njGUZ6tGdsXm",
        "outputId": "d98ddb55-d86a-4b75-96b9-85a27d9b47b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            " Cơ quan CSĐT Bộ Công an ngày 7-6 đã ra quyết định khởi tố bị can, bắt tạm giam ông Chu Ngọc Anh - cựu chủ tịch UBND TP Hà Nội, cựu Bộ trưởng KH&amp;CN; ông Nguyễn Thanh Long, cựu bộ trưởng Bộ Y tế và ông Phạm Công Tạc, cựu thứ trưởng Bộ KH&amp;CN để điều tra sai phạm liên quan vụ kit test Việt Á.\n",
            "Trao đổi với Pháp luật TP.HCM, đại biểu Quốc hội (ĐBQH) Phạm Văn Hòa, đoàn Đồng Tháp, Ủy viên Ủy ban Pháp luật của QH đánh giá diễn biến tố tụng trên cho thấy quan điểm “không có vùng cấm” trong công tác phòng, chống tham nhũng của Đảng và Nhà nước.\n",
            ". Phóng viên: Ông đánh giá như thế nào về việc Cơ quan CSĐT Bộ Công an cùng lúc khởi tố, bắt tạm giam ba cán bộ cấp cao, trong đó có tới hai người từng đứng đầu hai bộ ngành?\n",
            "+ Ông Phạm Văn Hòa: Đây là một hành động hết sức cương quyết, thể hiện được quyết tâm của Đảng và Nhà nước trong công tác phòng chống tham nhũng, chống lãng phí. \n",
            "Thời gian qua, tình hình tham nhũng, tiêu cực, lãng phí trong một bộ phận cán bộ có chức có quyền của nước ta khiến nhân dân hết rất bức xúc. Yêu cầu đặt ra là cần xử lý nghiêm, đặc biệt là các cấp lãnh đạo quản lý.\n",
            "Tôi cho rằng đây là vấn đề hết sức hệ trọng, xử lý sai phạm và xử lý trách nhiệm hình sự thì không có “vùng cấm”, dù cá nhân có chức vụ cao cấp đến đâu. \n",
            "Vấn đề xử lý sai phạm, khởi tố, bắt tạm giam cán bộ cấp cao cũng không phải chưa từng có tiền lệ. Trước đó, cơ quan CSĐT cũng đã bắt và xử lý sai phạm một số Ủy viên Trung ương Đảng, Bộ trưởng, Bí thư tỉnh ủy… \n",
            "Hành động này chắc chắn cũng phù hợp với mong muốn của người dân về công tác chống tham nhũng, chống lãng phí, bất kể người đó là ai. Với hy vọng bộ máy chính quyền nhà nước phục vụ nhân dân ngày càng trong sạch, vững mạnh và các cán bộ công chức sẽ có một phẩm chất đạo đức tốt để phục vụ nhân dân. \n",
            "Theo tôi, đây còn là sự cảnh tỉnh cho tất cả cán bộ trong hệ thống chính trị, không trừ ngành nào. Và vụ việc này cũng sẽ là “quả bom” cảnh báo mạnh mẽ đối với đội ngũ cán bộ công chức hiện nay. Đặc biệt là những Đảng viên có chức có quyền, cần nêu gương để họ nhìn vào sẽ không dám, không ham, không muốn và đừng phút giây nào lơi lỏng sự rèn luyện.\n",
            ".Tính đến nay đã có khoảng 60 người bị truy cứu trách nhiệm hình sự liên quan vụ kit test Việt Á, các bị can là cựu cán bộ của nhiều địa phương, bộ, ngành. Theo ông, đây đã phải là “hồi kết” cho vụ án?\n",
            "+ Tôi cho rằng đây vẫn chưa phải hồi kết cho vụ việc liên quan đến công ty Việt Á. Trong quá trình điều tra, cơ quan công an phát hiện tới đâu sẽ xử lý tới đó, đúng người đúng tội nên công tác phòng chống tham nhũng sẽ còn kéo dài.\n",
            "Tùy theo mức độ sai phạm sẽ có những hình thức xử lý khác nhau, nhẹ thì xử lý hành chính, nặng thì sẽ phải truy cứu trách nhiệm hình sự. \n",
            "Việc các cá nhân có phạm tội hay không thì chúng ta phải chờ cơ quan chức năng vào cuộc điều tra và các phán quyết từ tòa án.\n",
            ". Đại dịch COVID-19 đã cướp đi hàng ngàn sinh mạng, ảnh hưởng nặng nề đến mọi mặt cuộc sống nhưng nhiều cá nhân đã trục lợi trên nỗi đau của người dân. Là ĐBQH, đại diện tiếng nói cho của nhân dân, ông đánh giá như thế nào về việc này?\n",
            "+ Vi phạm thì phải bị xử lý. Bởi hành vi trục lợi cá nhân, lợi dụng tình hình dịch bệnh khó khăn để làm giàu, làm thất thoát ngân sách của nhà nước là hành vi bất chính và phải bị trừng trị.\n",
            "Trân trọng cảm ơn ông!\n",
            "Ngày 7-6, QH đã bãi nhiệm tư cách ĐBQH, cách chức bộ trưởng Bộ Y tế với ông Nguyễn Thanh Long vì các vi phạm đã được cơ quan chức năng kết luận. Ông Nguyễn Thanh Long không đảm bảo tiêu chuẩn là ĐBQH cũng như tư cách là bộ trưởng Bộ Y tế. Trước đó, chiều 6-6, Ban chấp hành Trung ương Đảng quyết định thi hành khai trừ ra khỏi Đảng với ông Nguyễn Thanh Long.\n",
            "Cùng ngày, HĐND TP Hà Nội thống nhất bãi miễn đại biểu HĐND với ông Chu Ngọc Anh. Các đại biểu cũng bãi miễn chức chủ tịch UBND TP Hà Nội với ông này. Trước đó, chiều 6-6, Ban chấp hành Trung ương Đảng quyết định thi hành khai trừ ra khỏi Đảng với ông Chu Ngọc Anh.\n",
            "Với ông Phạm Công Tạc, thứ trưởng Bộ KH&amp;CN, ngày 6-6, ông bị kỷ luật buộc thôi việc. Hôm 4-6, ông bị Ban bí thư khai trừ ra khỏi Đảng.\n",
            "Trong chiều tối 7-6, Bộ Công an đã có quyết định khởi tố bị can, bắt tạm giam ông Nguyễn Thanh Long, cựu bộ trưởng Bộ Y tế, về tội lợi dụng chức vụ quyền hạn trong khi thi hành công vụ; khởi tố bị can, bắt tạm giam ông Chu Ngọc Anh, cựu chủ tịch UBND TP Hà Nội, cựu bộ trưởng Bộ KH&amp;CN và ông Phạm Công Tạc, cựu thứ trưởng Bộ KH&amp;CN về tội vi phạm quy định về quản lý, sử dụng tài sản Nhà nước gây thất thoát, lãng phí.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HuZVN-r2jzb",
        "outputId": "c02b40e6-8d07-4c11-9d9a-0b4a8d26dfdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 16.2 MB/s \n",
            "\u001b[?25hCollecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.64.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.8 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import regex as re\n",
        "from pyvi import ViTokenizer, ViPosTagger\n",
        "\n",
        "bang_nguyen_am= [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
        "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
        "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
        "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
        "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
        "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
        "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
        "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
        "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
        "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
        "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
        "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
        "\n",
        "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
        "nguyen_am_to_ids = {}\n",
        "\n",
        "for i in range(len(bang_nguyen_am)):\n",
        "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
        "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
        "\n",
        "# Chuẩn hóa unicode \n",
        "# Có 2 loại unicode : unicode tổ hơp và unicode dựng sẵn, điêu này dẫn tới việc 2 từ giống nhau sẽ bị coi là khác nhau \n",
        "# Chuẩn hóa tất cả về 1 loại là unicode dựng sẵn\n",
        "def chuan_hoa_unicode(text):\n",
        "\ttext = unicodedata.normalize('NFC', text)\n",
        "\treturn text\n",
        "\n",
        "# Có 2 kiểu gõ dấu ở Tiếng Việt, ví dụ như là : òa hoặc oà (ta gọi lần lượt là chuẩn 1 và 2). Mặc dù kiểu gõ chữ sau ít \n",
        "#phổ biến hơn tuy nhiên vẫn cần phải chuẩn hóa tránh việc một số văn bản vẫn sử dụng kiểu gõ dấu thứ 2.\n",
        "\"\"\"\n",
        "\tHàm này xử lý chuẩn hóa từng từ một, sau khi chuẩn hóa từng từ thì ta sẽ đi chuân hóa từng câu sau \n",
        "\t\"\"\" \n",
        "def chuan_hoa_dau_tu_tieng_viet(word):\n",
        "    if not is_valid_vietnam_word(word):\n",
        "        return word\n",
        " \n",
        "    chars = list(word)\n",
        "    dau_cau = 0\n",
        "    nguyen_am_index = []\n",
        "    qu_or_gi = False\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x == -1:\n",
        "            continue\n",
        "        elif x == 9:  # check qu\n",
        "            if index != 0 and chars[index - 1] == 'q':\n",
        "                chars[index] = 'u'\n",
        "                qu_or_gi = True\n",
        "        elif x == 5:  # check gi\n",
        "            if index != 0 and chars[index - 1] == 'g':\n",
        "                chars[index] = 'i'\n",
        "                qu_or_gi = True\n",
        "        if y != 0:\n",
        "            dau_cau = y\n",
        "            chars[index] = bang_nguyen_am[x][0]\n",
        "        if not qu_or_gi or index != 1:\n",
        "            nguyen_am_index.append(index)\n",
        "    if len(nguyen_am_index) < 2:\n",
        "        if qu_or_gi:\n",
        "            if len(chars) == 2:\n",
        "                x, y = nguyen_am_to_ids.get(chars[1])\n",
        "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
        "            else:\n",
        "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
        "                if x != -1:\n",
        "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
        "                else:\n",
        "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
        "            return ''.join(chars)\n",
        "        return word\n",
        " \n",
        "    for index in nguyen_am_index:\n",
        "        x, y = nguyen_am_to_ids[chars[index]]\n",
        "        if x == 4 or x == 8:  # ê, ơ\n",
        "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
        "            # for index2 in nguyen_am_index:\n",
        "            #     if index2 != index:\n",
        "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
        "            #         chars[index2] = bang_nguyen_am[x][0]\n",
        "            return ''.join(chars)\n",
        " \n",
        "    if len(nguyen_am_index) == 2:\n",
        "        if nguyen_am_index[-1] == len(chars) - 1:\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
        "        else:\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "    else:\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
        "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
        "    return ''.join(chars)\n",
        " \n",
        " \n",
        "def is_valid_vietnam_word(word):\n",
        "    chars = list(word)\n",
        "    nguyen_am_index = -1\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x != -1:\n",
        "            if nguyen_am_index == -1:\n",
        "                nguyen_am_index = index\n",
        "            else:\n",
        "                if index - nguyen_am_index != 1:\n",
        "                    return False\n",
        "                nguyen_am_index = index\n",
        "    return True\n",
        "\n",
        "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
        "    \"\"\"\n",
        "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
        "        :param sentence:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "    # sentence = sentence.lower()\n",
        "    words = sentence.split()\n",
        "    for index, word in enumerate(words):\n",
        "        cw = re.sub(r'(^/p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
        "        # print(cw)\n",
        "        if len(cw) == 3:\n",
        "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
        "        words[index] = ''.join(cw)\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Tách từ tiếng việt, từ tiếng việt không giống như tiếng anh, tách từ tiếng anh ta chỉ cần tách bằng khoảng trắng\n",
        "# Tuy nhiên từ tiếng Việt có cả từ đơn lẫn từ ghép nên tách từ tiêng Việt sẽ phúc tạp hơn \n",
        "# Project sử dung thu viện pyvi (xem mã nguồn tại : https://github.com/trungtv/pyvi) để phục vụ bài toán con tách từ Tiếng Việt \n",
        "def tach_tu_tieng_viet(text):\n",
        "\ttext = ViTokenizer.tokenize(text)\n",
        "\treturn text\n",
        "\n",
        "# Đưa về chữ viết thường \n",
        "def chuyen_chu_thuong(text):\n",
        "\treturn text.lower()\n",
        "\n",
        "# Xóa đi các dấu cách thừa, các từ không cần thiết cho việc phân loại vẳn bản \n",
        "def chuan_hoa_cau(text):\n",
        "\ttext = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',text)\n",
        "\ttext = re.sub(r'\\s+', ' ', text).strip()\n",
        "\treturn text\n",
        "\n",
        "def tien_xu_li(text):\n",
        "\ttext = chuan_hoa_unicode(text)\n",
        "\ttext = chuan_hoa_dau_cau_tieng_viet(text)\n",
        "\ttext = tach_tu_tieng_viet(text)\n",
        "\ttext = chuyen_chu_thuong(text)\n",
        "\ttext = chuan_hoa_cau(text)\n",
        "\n",
        "\treturn text"
      ],
      "metadata": {
        "id": "9khsLecpxe9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = content[0]\n",
        "print(text)\n",
        "print(chuan_hoa_unicode(text))\n",
        "print(chuan_hoa_dau_cau_tieng_viet(text))\n",
        "print(chuan_hoa_cau(text))\n",
        "print(tach_tu_tieng_viet(text))\n",
        "print(tien_xu_li(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_fbedlx3iT0",
        "outputId": "c298b9fd-1b6d-4953-e03a-6d916d6ec1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Cơ quan CSĐT Bộ Công an ngày 7-6 đã ra quyết định khởi tố bị can, bắt tạm giam ông Chu Ngọc Anh - cựu chủ tịch UBND TP Hà Nội, cựu Bộ trưởng KH&amp;CN; ông Nguyễn Thanh Long, cựu bộ trưởng Bộ Y tế và ông Phạm Công Tạc, cựu thứ trưởng Bộ KH&amp;CN để điều tra sai phạm liên quan vụ kit test Việt Á.\n",
            " Cơ quan CSĐT Bộ Công an ngày 7-6 đã ra quyết định khởi tố bị can, bắt tạm giam ông Chu Ngọc Anh - cựu chủ tịch UBND TP Hà Nội, cựu Bộ trưởng KH&amp;CN; ông Nguyễn Thanh Long, cựu bộ trưởng Bộ Y tế và ông Phạm Công Tạc, cựu thứ trưởng Bộ KH&amp;CN để điều tra sai phạm liên quan vụ kit test Việt Á.\n",
            "Cơ quan CSĐT Bộ Công an ngày 7-6 đã ra quyết định khởi tố bị can, bắt tạm giam ông Chu Ngọc Anh - cựu chủ tịch UBND TP Hà Nội, cựu Bộ trưởng KH&amp;CN; ông Nguyễn Thanh Long, cựu bộ trưởng Bộ Y tế và ông Phạm Công Tạc, cựu thứ trưởng Bộ KH&amp;CN để điều tra sai phạm liên quan vụ kit test Việt Á.\n",
            "Cơ quan CSĐT Bộ Công an ngày 7 6 đã ra quyết định khởi tố bị can bắt tạm giam ông Chu Ngọc Anh cựu chủ tịch UBND TP Hà Nội cựu Bộ trưởng KH amp CN ông Nguyễn Thanh Long cựu bộ trưởng Bộ Y tế và ông Phạm Công Tạc cựu thứ trưởng Bộ KH amp CN để điều tra sai phạm liên quan vụ kit test Việt Á\n",
            "Cơ_quan CSĐT Bộ Công_an ngày 7 - 6 đã ra quyết_định khởi_tố bị_can , bắt tạm giam ông Chu_Ngọc_Anh - cựu_chủ_tịch UBND TP Hà_Nội , cựu Bộ_trưởng KH & amp ; CN ; ông Nguyễn Thanh_Long , cựu bộ_trưởng Bộ Y_tế và ông Phạm Công_Tạc , cựu thứ_trưởng Bộ KH & amp ; CN để điều_tra sai_phạm liên_quan vụ kit test Việt_Á .\n",
            "cơ_quan csđt bộ công_an ngày 7 6 đã ra quyết_định khởi_tố bị_can bắt tạm giam ông chu_ngọc_anh cựu_chủ_tịch ubnd tp hà_nội cựu bộ_trưởng kh amp cn ông nguyễn thanh_long cựu bộ_trưởng bộ y_tế và ông phạm công_tạc cựu thứ_trưởng bộ kh amp cn để điều_tra sai_phạm liên_quan vụ kit test việt_á\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2xsELYo73ZI",
        "outputId": "6c8d4e3d-18bc-4f17-dc83-8b48c38e035d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bknj9puJ7ycD",
        "outputId": "7bd477bc-135b-4e73-9772-5543536a5ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "choices = [\"Lê Thanh Tùng\", \"Le Thanh Tung\", \"le thanhtùng\", \"le Tah tùg\", \"le Thah tùgn\", \"Le Tung\", \"Nguyễn Thành Long\", \"Lê Mỹ Hạnh\", \"Lê Thanh Lân\", \"Lê Hoàng Tùng\", \"Lưu Hoàng Tùng\"]\n",
        "\n",
        "print(process.extract(\"Lê Thanh Tùng\", choices,limit=10))\n",
        "\n",
        "res = process.extractBests(\"Lê Thanh Tùng\", choices,limit=10,score_cutoff=80)\n",
        "print(res)\n",
        "\n",
        "print(process.extractOne(\"Lê Thanh Tùng\", choices))\n",
        "\n",
        "print(fuzz.ratio(\"Lê\",\"Lưu\"))\n",
        "print(fuzz.ratio(\"Thanh\",\"Hoàng\"))\n",
        "print(fuzz.ratio(\"Tùng\",\"Lân\"))\n",
        "\n",
        "# def compare_text(name,candidate):\n",
        "#   text = "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxLRxlln79qK",
        "outputId": "73076309-d31e-4a02-8c86-f810625923da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Lê Thanh Tùng', 100), ('Le Thanh Tung', 92), ('le thanhtùng', 91), ('Lê Thanh Lân', 86), ('le Thah tùgn', 82), ('le Tah tùg', 80), ('Lê Hoàng Tùng', 76), ('Lưu Hoàng Tùng', 70), ('Nguyễn Thành Long', 59), ('Lê Mỹ Hạnh', 57)]\n",
            "[('Lê Thanh Tùng', 100), ('Le Thanh Tung', 92), ('le thanhtùng', 91), ('Lê Thanh Lân', 86), ('le Thah tùgn', 82), ('le Tah tùg', 80)]\n",
            "('Lê Thanh Tùng', 100)\n",
            "40\n",
            "20\n",
            "29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5vXEyJFL99Jn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}