{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79721b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('mimetype')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 100\n",
    "import altair as alt\n",
    "alt.renderers.enable('mimetype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0b4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig()  # Means logs will print in Jupyter Lab\n",
    "\n",
    "# Set to DEBUG if you want splink to log the SQL statements it's executing under the hood\n",
    "logging.getLogger(\"splink\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00185d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/14 11:00:34 WARN SimpleFunctionRegistry: The function jaro_winkler_sim replaced a previously registered function.\n",
      "22/06/14 11:00:34 WARN SimpleFunctionRegistry: The function dmetaphone replaced a previously registered function.\n"
     ]
    }
   ],
   "source": [
    "from utility_functions.demo_utils import get_spark\n",
    "spark = get_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b822ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4cd419b580>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44631623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hospital_accounts = spark.read.csv('./sample/hospital_account_info.csv',header=True,inferSchema=True)\n",
    "hospital_reimbursement = spark.read.csv('./sample/hospital_reimbursement.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46470f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------\n",
      " unique_id          | 10605                          \n",
      " Facility Name      | SAGE MEMORIAL HOSPITAL         \n",
      " Address            | STATE ROUTE 264 SOUTH 191      \n",
      " City               | GANADO                         \n",
      " State              | AZ                             \n",
      " ZIP Code           | 86505                          \n",
      " County Name        | APACHE                         \n",
      " Phone Number       | (928) 755-4541                 \n",
      " Hospital Type      | Critical Access Hospitals      \n",
      " Hospital Ownership | Voluntary non-profit - Private \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0-----------------------------------------------------\n",
      " Provider_Num              | 839987                           \n",
      " Provider Name             | SOUTHEAST ALABAMA MEDICAL CENTER \n",
      " Provider Street Address   | 1108 ROSS CLARK CIRCLE           \n",
      " Provider City             | DOTHAN                           \n",
      " Provider State            | AL                               \n",
      " Provider Zip Code         | 36301                            \n",
      " Total Discharges          | 118                              \n",
      " Average Covered Charges   | 20855.61                         \n",
      " Average Total Payments    | 5026.19                          \n",
      " Average Medicare Payments | 4115.52                          \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hospital_accounts.show(1,truncate=False,vertical=True)\n",
    "hospital_reimbursement.show(1,truncate=False,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7179b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_accounts = hospital_accounts.withColumnRenamed(\"Account_Num\",\"unique_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d55140a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules\": [],\n",
    "    \"comparison_columns\": [\n",
    "        {\n",
    "            \"col_name\": \"Facility Name\"\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"Address\"\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"City\"\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"State\"\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6453e4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/14 11:13:18 WARN MemoryStore: Not enough space to cache rdd_177_0 in memory! (computed 1879.6 MiB so far)\n",
      "22/06/14 11:13:18 WARN BlockManager: Block rdd_177_0 could not be removed as it was not found on disk or in memory\n",
      "22/06/14 11:13:18 WARN BlockManager: Putting block rdd_177_0 failed\n",
      "INFO:splink.iterate:Iteration 0 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 0.8997805545637466 for key Address, level 0\n",
      "INFO:splink.iterate:Iteration 1 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 0.03909884657917312 for key City, level 1\n",
      "INFO:splink.iterate:Iteration 2 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 0.01241580521015842 for key City, level 1\n",
      "INFO:splink.iterate:Iteration 3 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 0.005250325827393043 for key State, level 1\n",
      "INFO:splink.iterate:Iteration 4 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 0.002468668651302214 for key State, level 0\n",
      "INFO:splink.iterate:Iteration 5 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 0.0011686688006960766 for key State, level 0\n",
      "INFO:splink.iterate:Iteration 6 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 0.000556263278658875 for key State, level 1\n",
      "INFO:splink.iterate:Iteration 7 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 0.00026656235352096047 for key State, level 0\n",
      "INFO:splink.iterate:Iteration 8 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 0.00012923645071971634 for key State, level 1\n",
      "INFO:splink.iterate:Iteration 9 complete                                        \n",
      "INFO:splink.model:The maximum change in parameters was 6.407651588336005e-05 for key State, level 1\n",
      "INFO:splink.iterate:EM algorithm has converged\n"
     ]
    }
   ],
   "source": [
    "from splink import Splink\n",
    "\n",
    "linker = Splink(settings, hospital_accounts, spark)\n",
    "df_e = linker.get_scored_comparisons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa072a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/14 11:18:46 WARN MemoryStore: Not enough space to cache rdd_177_0 in memory! (computed 1879.6 MiB so far)\n",
      "22/06/14 11:18:46 WARN BlockManager: Block rdd_177_0 could not be removed as it was not found on disk or in memory\n",
      "22/06/14 11:18:46 WARN BlockManager: Putting block rdd_177_0 failed\n",
      "22/06/14 11:19:36 ERROR Utils: Uncaught exception in thread task-result-getter-1\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$readExternal$1(TaskResult.scala:62)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2545/762095392.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1428)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.readExternal(TaskResult.scala:60)\n",
      "\tat java.io.ObjectInputStream.readExternalData(ObjectInputStream.java:2236)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2185)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:109)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:97)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3$$Lambda$2544/693315282.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2019)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Exception in thread \"task-result-getter-1\" java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$readExternal$1(TaskResult.scala:62)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2545/762095392.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1428)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.readExternal(TaskResult.scala:60)\n",
      "\tat java.io.ObjectInputStream.readExternalData(ObjectInputStream.java:2236)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2185)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:109)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:97)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3$$Lambda$2544/693315282.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2019)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "cols_to_inspect = [\"match_probability\", \"match_weight\", \"unique_id_l\", \"unique_id_r\", \\\n",
    "                   \"Facility Name_l\", \"Facility Name_r\", \"Address_l\", \"Address_r\", \\\n",
    "                   \"City_l\", \"City_r\", \"State_l\", \"State_r\"]\n",
    "\n",
    "df_e.toPandas()[cols_to_inspect].sort_values([\"unique_id_l\", \"unique_id_r\"]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c522e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql_case_expression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142120/3606727167.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;34m\"custom_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"name_inversion\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;34m\"custom_columns_used\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"first_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"surname\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;34m\"case_expression\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msql_case_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;34m\"num_levels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         },\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sql_case_expression' is not defined"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "    \"link_type\": \"link_only\", \n",
    "    \"max_iterations\": 20,\n",
    "    \"blocking_rules\": [\n",
    "    ],\n",
    "    \"comparison_columns\": [\n",
    "       {\n",
    "            \"custom_name\": \"name_inversion\",\n",
    "            \"custom_columns_used\": [\"first_name\", \"surname\"],\n",
    "            \"case_expression\": sql_case_expression,\n",
    "            \"num_levels\": 5\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"city\",\n",
    "            \"num_levels\": 3\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"email\",\n",
    "            \"num_levels\": 3\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"dob\"\n",
    "        }\n",
    "    ],\n",
    "    \"additional_columns_to_retain\": [\"group\"],\n",
    "    \"em_convergence\": 0.01,\n",
    "    \"max_iterations\": 4,\n",
    "}\n",
    "\n",
    "compare.exact('City', 'Provider City', label='City')\n",
    "compare.string('Facility Name',\n",
    "            'Provider Name',\n",
    "            threshold=0.85,\n",
    "            label='Hosp_Name')\n",
    "compare.string('Address',\n",
    "            'Provider Street Address',\n",
    "            method='jarowinkler',\n",
    "            threshold=0.85,\n",
    "            label='Hosp_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink import Splink  \n",
    "linker = Splink(settings, spark, df=df) \n",
    "df_e = linker.get_scored_comparisons()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
